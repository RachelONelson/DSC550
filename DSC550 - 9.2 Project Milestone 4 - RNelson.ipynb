{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 9.2 Project Milestone #4\n",
    "author: Rachel Nelson\n",
    "\n",
    "class: DSC550-T302 Data Mining (2215-1)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Milestone 1: Narrative\n",
    "\n",
    "### Avocado Market\n",
    "\n",
    "In this scenario, I am helping an avocado farmer predict what the prices of avocados will be in order to help with budgeting and forecasting. I want to see if there are specific “tells” or levers and pulls that can be used to predict when pricing will change. By knowing this information, I would be able to determine when and how avocado prices fluctuate, which would be helpful to the farmer. This scenario will use the data set “avocado” which is available on Kaggle at https://www.kaggle.com/neuromusic/avocado-prices.\n",
    "I will be looking at 13 different features which include the date, average prices, total volume, total numbers of avocados with PLU 4046 sold, total numbers of avocados with PLU 4225 sold, Total number of avocados with PLU 4770 sold, total bags, total small bags, and total large bags, total extra large bags, avocado type, year and region.\n",
    "\n",
    "\n",
    "#### Questions that might help me predict avocado prices:\n",
    "\n",
    "1. What do the variables look like? For example, are they numerical or categorical data. If they are numerical, what are their distribution; if they are categorical, how many are they in different categories?\n",
    "\n",
    "2. Are the numerical variables correlated?\n",
    "\n",
    "3. How to avocado prices fluctuate over time?\n",
    "\n",
    "4. can i predict the avocado prices?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Milestone 1: graphical analysis creating a minimum of four graphs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yellowbrick\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from yellowbrick.features import Rank2D"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Load the data\n",
    "data = \"C:/Users/emera/Downloads/avocado/avocado.csv\"\n",
    "data = pd.read_csv(\"C:/Users/emera/Downloads/avocado/avocado.csv\", parse_dates=[\"Date\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Step 2:  check the dimension of the table\n",
    "print(\"The dimension of the table is: \", data.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Step 3:  Look at the data\n",
    "print(data.head(5))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#4.\tThink about some questions that might help you predict who will survive:\n",
    "#a.\tWhat do the variables look like? For example, are they numerical or categorical data. If they are numerical, what are their distribution; if they are categorical, how many are they in different categories?\n",
    "print(\"Variable Information\")\n",
    "data.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#b.\tAre the numerical variables correlated?\n",
    "print(\"Correlation Matrix\")\n",
    "data.corr()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Are the distributions of numerical variables the same or different among regions?\n",
    "fig = plt.figure(figsize=(18,6))      ## To get a figure with proper structure\n",
    "data.region.value_counts().plot(kind=\"bar\",alpha=0.5)  ## Setting alpha as per transparency"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Are the distributions of numerical variables the same or different among different types?\n",
    "fig = plt.figure(figsize=(18,6))      ## To get a figure with proper structure\n",
    "data.type.value_counts().plot(kind=\"bar\",alpha=0.5)  #"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#5.\tLook at summary information about your data (total, mean, min, max, freq, unique, etc.)  Does this present any more questions for you?  Does it lead you to a conclusion yet?\n",
    "print(\"Describe Data\")\n",
    "print(data.describe())\n",
    "print(\"Summarized Data\")\n",
    "print(data.describe(include=['O']))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# histograms\n",
    "data.hist(bins=15,figsize=(9,7),grid=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#7.\tBar charts for variables\n",
    "data.type.value_counts().plot(kind='bar', alpha=0.55)\n",
    "plt.title(\"Observations by Type\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data.year.value_counts().plot(kind='bar', alpha=0.55)\n",
    "plt.title(\"Observations by Year\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data.region.value_counts().plot(kind='bar', alpha=0.55)\n",
    "plt.title(\"Observations by Region\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#8.\tTo see if the data is correlated, make some Pearson Ranking charts\n",
    "corr=data.corr()\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "sns.heatmap(corr, vmax=.8, linewidths=0.01,\n",
    "            square=True,annot=True,cmap='YlGnBu',linecolor=\"white\")\n",
    "plt.title('Pearson Ranking Chart');\n",
    "#a.\tNotice that in my sample code, I have saved this png file.\n",
    "#b.\tThe correlation between the variables is low (1 or -1 is high positive or high negative, 0 is low or no correlation)  These results show there is “some” positive correlation but it’s not a high correlation."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_features = ['Total Volume', 'AveragePrice', 'Total Bags', 'year']\n",
    "xaxes = num_features\n",
    "yaxes = ['Counts', 'Counts', 'Counts', 'Counts']\n",
    "X = data[num_features].to_numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# instantiate the visualizer with the Covariance ranking algorithm\n",
    "visualizer = Rank2D(features=num_features, algorithm='pearson')\n",
    "visualizer.fit(X)                # Fit the data to the visualizer\n",
    "visualizer.transform(X)             # Transform the data\n",
    "visualizer.poof(outpath=\"d://covariance1.png\") # Draw/show/poof the data\n",
    "#plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#9.\t Use Parallel Coordinates visualization to compare the distributions of numerical variables between organic and conventional"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# import packages\n",
    "from yellowbrick.style import set_palette\n",
    "from yellowbrick.features import ParallelCoordinates\n",
    "set_palette('sns_bright')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Specify the features of interest and the classes of the target\n",
    "data.loc[data['type'] == 'conventional','type_1'] = 1\n",
    "data.loc[data['type'] == 'organic','type_1'] = 0\n",
    "print(data.head(5))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "classes = ['conventional', 'organic']\n",
    "num_features = ['Total Volume', 'AveragePrice', 'Total Bags', 'year']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# copy data to a new dataframe\n",
    "data_norm = data.copy()\n",
    "# normalize data to 0-1 range\n",
    "for feature in num_features:\n",
    "    data_norm[feature] = (data[feature] - data[feature].mean(skipna=True)) / (data[feature].max(skipna=True) - data[feature].min(skipna=True))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Extract the numpy arrays from the data frame\n",
    "X = data_norm[num_features].to_numpy()\n",
    "y = data.type.to_numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Instantiate the visualizer\n",
    "# Instantiate the visualizer\n",
    "visualizer = ParallelCoordinates(classes=classes, features=num_features)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "visualizer.fit(X, y)      # Fit the data to the visualizer\n",
    "visualizer.transform(X)   # Transform the data\n",
    "visualizer.poof(outpath=\"d://avocadocoords3.png\") # Draw/show/poof the data\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "###  Graphical Analysis Conclusion:\n",
    "\n",
    "#### Distribution\n",
    "The data looks even distributed among different types and regions.\n",
    "The data does not look like it includes more then a quarter of 2018 when looking at the distribution by year\n",
    "\n",
    "#### Correlation\n",
    "There are no high correlations associated with the average price.\n",
    "There are high correlations between total volume, PLU's, and number of bags, which is expected since they are all volume metrics.\n",
    "\n",
    "#### Parallel Coordinates"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 7.3 Project Milestone #2\n",
    "author: Rachel Nelson\n",
    "\n",
    "class: DSC550-T302 Data Mining (2215-1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Milestone 2: dimensionality/feature reduction and feature engineering steps\n",
    "* Drop any features that are not useful for your model building. You should explain and justify why the feature dropped is not useful.\n",
    "* address any missing data issues.\n",
    "* Build any new features that you need for your model, e.g., create dummy variables for categorical features if necessary."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yellowbrick\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from yellowbrick.features import Rank2D"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# drop feature \"year\" since I already have the date also dropped \"unnamed\" because it is not needed\n",
    "data =  data.drop(columns=[\"year\",\"Unnamed: 0\"])\n",
    "data.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# address any missing data issues\n",
    "print(data.describe())\n",
    "data.isnull().values.any()\n",
    "# there is no missing data in the data set\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# create dummy variables for categorical features (did not end\n",
    "features = ['type', 'region']\n",
    "df = data[features]\n",
    "\n",
    "# One Hot Encoding\n",
    "df = pd.get_dummies(df)\n",
    "\n",
    "# check the data\n",
    "print(df.head(5))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Milestone 3: model selection and evaluation\n",
    "* build and evaluate at least one model.\n",
    "\n",
    "I'm tried to find good examples of ARIMA models. used the following resources for reference:\n",
    "\n",
    "Supports:\n",
    "https://towardsdatascience.com/machine-learning-part-19-time-series-and-autoregressive-integrated-moving-average-model-arima-c1005347b0d7\n",
    "https://machinelearningmastery.com/arima-for-time-series-forecasting-with-python/\n",
    "https://salcorpenterprise.com/time-series-analysis-with-avocados/\n",
    "https://www.kaggle.com/dhimananubhav/forecasting-avocado-prices-statsmodels-mape-8"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Initial approximation of parameters\n",
    "cols = ['Date', 'AveragePrice', 'type', 'region']\n",
    "df = data[cols]\n",
    "\n",
    "# I really just want the TotalUS region and the conventional avocado types\n",
    "df = df[(df.region =='TotalUS') & (df.type == 'conventional') ] #& (df.Date >= '2016-01-01')\n",
    "\n",
    "# removing region and type from the data set\n",
    "del df['region']\n",
    "del df['type']\n",
    "\n",
    "# sorting the values by date\n",
    "df = df.sort_values(\"Date\")\n",
    "\n",
    "df.columns = ['ds', 'y']\n",
    "df.set_index('ds', inplace=True)\n",
    "\n",
    "# Split datasets into train and test sets\n",
    "train = df[:-12]\n",
    "test = df[-12:]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(12, 8)\n",
    "\n",
    "ax = sns.scatterplot(x=train.index, y=train.y)\n",
    "ax = sns.scatterplot(x=test.index, y=test.y)\n",
    "\n",
    "ax.axes.set_xlim(train.index.min(), test.index.max())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Import additional packages\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from scipy import stats\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# This is a very interesting Dickey-Fuller test - needed this test in order for ARIMA to function\n",
    "train['y_box'], lmbda = stats.boxcox(train.y)\n",
    "seasonal_decompose(train.y_box, model='additive').plot()\n",
    "print(\"Dickey–Fuller test: p=%f\" % adfuller(train.y_box)[1])\n",
    "# notice that the p < 0.05 which means that the series is stationary"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Model Selection\n",
    "results = []\n",
    "best_aic = float(\"inf\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for param in parameters_list:\n",
    "    try:\n",
    "        model = SARIMAX(train.y_box, order=(param[0], d, param[1])).fit(disp=-1)\n",
    "    except ValueError:\n",
    "        print('bad parameter combination:', param)\n",
    "        continue\n",
    "    aic = model.aic\n",
    "    if aic < best_aic:\n",
    "        best_model = model\n",
    "        best_aic = aic\n",
    "        best_param = param\n",
    "    results.append([param, model.aic])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Best Models\n",
    "result_table = pd.DataFrame(results)\n",
    "result_table.columns = ['parameters', 'aic']\n",
    "print(result_table.sort_values(by='aic', ascending=True).head())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(best_model.summary())\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}