{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 4.2 Exercise: Sentiment Analysis\n",
    "author: Rachel Nelson\n",
    "\n",
    "class: DSC550-T302 Data Mining (2215-1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this exercise, you will do a sentiment analysis of text comments.\n",
    "\n",
    "Load the data file DailyComments.csv from the Week 4 Data Files into a data frame.\n",
    "Identify a scheme to categorize each comment as positive or negative. You can devise your own scheme or find a commonly used scheme to perform this sentiment analysis. However you decide to do this, make sure to explain the scheme you decide to use.\n",
    "Implement your sentiment analysis with code and display the results. Note: DailyComments.csv is a purposely small file, so you will be able to clearly see why the results are what they are.\n",
    "For up to 5% extra credit, find another set of comments, e.g., some tweets, and perform the same sentiment analysis.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import seaborn as sns\n",
    "pd.set_option('display.max_colwidth',0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "data": {
      "text/plain": "  Day of Week                                        comments\n0  Monday      Hello, how are you?                           \n1  Tuesday     Today is a good day!                          \n2  Wednesday   It's my birthday so it's a really special day!\n3  Thursday    Today is neither a good day or a bad day!     \n4  Friday      I'm having a bad day.                         ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Day of Week</th>\n      <th>comments</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Monday</td>\n      <td>Hello, how are you?</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Tuesday</td>\n      <td>Today is a good day!</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Wednesday</td>\n      <td>It's my birthday so it's a really special day!</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Thursday</td>\n      <td>Today is neither a good day or a bad day!</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Friday</td>\n      <td>I'm having a bad day.</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data file DailyComments.csv from the Week 4 Data Files into a data frame.\n",
    "df = pd.read_csv(\"D:\\machine-learning-with-python-cookbook\\week-4\\DailyComments.csv\")\n",
    "df = pd.DataFrame(df)\n",
    "df.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['are', 'bad', 'birthday', 'day', 'good', 'happening', 'having', 'hello', 'how', 'is', 'it', 'my', 'neither', 'nothing', 'or', 'really', 'so', 'special', 'super', 'there', 'today', 'you']\n"
     ]
    }
   ],
   "source": [
    "# Identify a scheme to categorize each comment as positive or negative\n",
    "\n",
    "#uses count vectorizer transformer (page 58)\n",
    "corpus = df['comments']\n",
    "vectorizer = CountVectorizer()\n",
    "vectors = vectorizer.fit_transform(corpus)\n",
    "\n",
    "# Look at vectorized words, I'm using this to determine my positive and negative words (pg 113)\n",
    "print(vectorizer.get_feature_names())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             text  super  good  special  \\\n",
      "0  Hello, how are you?                             0      0     0         \n",
      "1  Today is a good day!                            0      1     0         \n",
      "2  It's my birthday so it's a really special day!  0      0     1         \n",
      "3  Today is neither a good day or a bad day!       0      1     0         \n",
      "4  I'm having a bad day.                           0      0     0         \n",
      "5  There' s nothing special happening today.       0      0     1         \n",
      "6  Today is a SUPER good day!                      0      1     0         \n",
      "\n",
      "   fantastic  totalpositive  bad  ashamed  totalnegative  TotalScore  \n",
      "0  0          0              0    0        0              0           \n",
      "1  0          1              0    0        0              1           \n",
      "2  0          1              0    0        0              1           \n",
      "3  0          1              1    0        1              0           \n",
      "4  0          0              1    0        1             -1           \n",
      "5  0          1              0    0        0              1           \n",
      "6  0          1              0    0        0              1           \n",
      "                                             text  super  good  special  \\\n",
      "0  Hello, how are you?                             0      0     0         \n",
      "1  Today is a good day!                            0      1     0         \n",
      "2  It's my birthday so it's a really special day!  0      0     1         \n",
      "3  Today is neither a good day or a bad day!       0      1     0         \n",
      "4  I'm having a bad day.                           0      0     0         \n",
      "5  There' s nothing special happening today.       0      0     1         \n",
      "6  Today is a SUPER good day!                      0      1     0         \n",
      "\n",
      "   fantastic  totalpositive  bad  ashamed  totalnegative  TotalScore  \n",
      "0  0          0              0    0        0              0           \n",
      "1  0          1              0    0        0              1           \n",
      "2  0          1              0    0        0              1           \n",
      "3  0          1              1    0        1              0           \n",
      "4  0          0              1    0        1             -1           \n",
      "5  0          1              0    0        0              1           \n",
      "6  0          1              0    0        0              1           \n",
      "Total Score: 3\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'text' : corpus})\n",
    "\n",
    "# check for positive words and negative words\n",
    "# Positive Words\n",
    "df['super'] = df.text.str.count('super')\n",
    "df['good'] = df.text.str.count('good')\n",
    "df['special']= df.text.str.count('special')\n",
    "df['fantastic']= df.text.str.count('fantastic')\n",
    "df['totalpositive'] = (df.super + df.good + df.special + df.fantastic)\n",
    "\n",
    "# Negative Words\n",
    "df['bad'] = df.text.str.count('bad')\n",
    "df['ashamed'] = df.text.str.count('ashamed')\n",
    "df['totalnegative'] = (df.bad + df.ashamed)\n",
    "#get a total score by adding the positives and subtracting the negative words\n",
    "df['TotalScore'] = (df.totalpositive) - (df.totalnegative)\n",
    "df = pd.DataFrame(df)\n",
    "print(df)\n",
    "\n",
    "Z = sum(df['TotalScore'])\n",
    "\n",
    "# Implement your sentiment analysis with code and display the results. Note: DailyComments.csv is a purposely small file, so you will be able to clearly see why the results are what they are.\n",
    "print(df)\n",
    "print(\"Total Score:\",Z)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "For up to 5% extra credit, find another set of comments, e.g., some tweets, and perform the same sentiment analysis.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                                            title  \\\n0  Health Canada approves AstraZeneca COVID-19 vaccine                              \n1  COVID-19 in Canada: 'Vaccination passports' a near certainty says bio-ethicist   \n2  Coronavirus variants could fuel Canada's third wave                              \n3  Canadian government to extend COVID-19 emergency benefits                        \n4  Canada: Pfizer is 'extremely committed' to meeting vaccine delivery targets      \n\n   score      id  \\\n0  7      lt74vw   \n1  2      lsh0ij   \n2  6      lohlle   \n3  1      lnptv8   \n4  6      lkslm6   \n\n                                                                                url  \\\n0  https://www.canadaforums.ca/2021/02/health-canada-approves-astrazeneca.html        \n1  https://www.canadaforums.ca/2021/02/covid-19-in-canada-vaccination.html            \n2  https://www.canadaforums.ca/2021/02/coronavirus-variants-could-fuel-canadas.html   \n3  https://www.canadaforums.ca/2021/02/canadian-government-to-extend-covid-19.html    \n4  https://www.canadaforums.ca/2021/02/canada-pfizer-is-extremely-committed-to.html   \n\n   comms_num       created body            timestamp  \n0  0          1.614400e+09  NaN  2021-02-27 06:33:45  \n1  1          1.614316e+09  NaN  2021-02-26 07:11:07  \n2  0          1.613887e+09  NaN  2021-02-21 07:50:08  \n3  0          1.613796e+09  NaN  2021-02-20 06:35:13  \n4  0          1.613468e+09  NaN  2021-02-16 11:36:28  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>score</th>\n      <th>id</th>\n      <th>url</th>\n      <th>comms_num</th>\n      <th>created</th>\n      <th>body</th>\n      <th>timestamp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Health Canada approves AstraZeneca COVID-19 vaccine</td>\n      <td>7</td>\n      <td>lt74vw</td>\n      <td>https://www.canadaforums.ca/2021/02/health-canada-approves-astrazeneca.html</td>\n      <td>0</td>\n      <td>1.614400e+09</td>\n      <td>NaN</td>\n      <td>2021-02-27 06:33:45</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>COVID-19 in Canada: 'Vaccination passports' a near certainty says bio-ethicist</td>\n      <td>2</td>\n      <td>lsh0ij</td>\n      <td>https://www.canadaforums.ca/2021/02/covid-19-in-canada-vaccination.html</td>\n      <td>1</td>\n      <td>1.614316e+09</td>\n      <td>NaN</td>\n      <td>2021-02-26 07:11:07</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Coronavirus variants could fuel Canada's third wave</td>\n      <td>6</td>\n      <td>lohlle</td>\n      <td>https://www.canadaforums.ca/2021/02/coronavirus-variants-could-fuel-canadas.html</td>\n      <td>0</td>\n      <td>1.613887e+09</td>\n      <td>NaN</td>\n      <td>2021-02-21 07:50:08</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Canadian government to extend COVID-19 emergency benefits</td>\n      <td>1</td>\n      <td>lnptv8</td>\n      <td>https://www.canadaforums.ca/2021/02/canadian-government-to-extend-covid-19.html</td>\n      <td>0</td>\n      <td>1.613796e+09</td>\n      <td>NaN</td>\n      <td>2021-02-20 06:35:13</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Canada: Pfizer is 'extremely committed' to meeting vaccine delivery targets</td>\n      <td>6</td>\n      <td>lkslm6</td>\n      <td>https://www.canadaforums.ca/2021/02/canada-pfizer-is-extremely-committed-to.html</td>\n      <td>0</td>\n      <td>1.613468e+09</td>\n      <td>NaN</td>\n      <td>2021-02-16 11:36:28</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data file into a data frame.\n",
    "# data from: https://www.kaggle.com/gpreda/reddit-vaccine-myths\n",
    "# Load the data file a data frame.\n",
    "df = pd.read_csv('D:\\machine-learning-with-python-cookbook\\week-4\\dditionalcomments.csv')\n",
    "df = pd.DataFrame(df)\n",
    "df.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['000', '0006', '10', '100', '1000', '100mcg', '12', '15', '150', '17', '18', '18th', '19', '1918', '200', '2002', '2013', '21', '27', '277', '300', '340', '38', '3m', '3rd', '400', '417', '43', '4x', '50', '500', '562', '5g', '6th', '80', '84', '85', '88', '90', '93', '99', 'abandon', 'abc', 'able', 'aborted', 'abortion', 'about', 'absolute', 'absolutely', 'absorbed', 'absurdity', 'academic', 'acceptable', 'acceptance', 'access', 'according', 'accurately', 'acellular', 'achievable', 'actively', 'activist', 'activistpost', 'actual', 'actually', 'ad', 'adamant', 'addicts', 'address', 'addressing', 'adha', 'adjuvants', 'administered', 'admit', 'admits', 'admitted', 'adopt', 'adult', 'adults', 'adverse', 'advocating', 'affect', 'affected', 'africa', 'african', 'after', 'again', 'against', 'agent', 'agents', 'agree', 'aid', 'aids', 'ain', 'alabama', 'alcohol', 'all', 'allegations', 'allergic', 'allergies', 'allergy', 'allow', 'allowances', 'almost', 'alphabet', 'already', 'alright', 'also', 'alters', 'altert', 'although', 'aluminum', 'always', 'am', 'ama', 'amalgams', 'american', 'americans', 'amid', 'amish', 'among', 'amongst', 'an', 'analysis', 'anaphylactic', 'and', 'andrew', 'angry', 'animal', 'annals', 'another', 'answer', 'anti', 'antibodies', 'antivaccinationists', 'antivaccine', 'antivax', 'antivaxxers', 'antivaxxvalentines', 'any', 'anybody', 'anyone', 'anything', 'apart', 'appalachian', 'apparent', 'apparently', 'applied', 'approaches', 'approval', 'approves', 'april', 'are', 'areas', 'aren', 'argued', 'argument', 'arguments', 'arose', 'around', 'article', 'as', 'asd', 'ashamed', 'ask', 'asked', 'asking', 'asks', 'aspect', 'aspergers', 'asping', 'aspirin', 'assassinated', 'associated', 'association', 'assuming', 'assurance', 'astrazeneca', 'at', 'attack', 'attempt', 'attention', 'atypical', 'aunt', 'author', 'authority', 'autisim', 'autism', 'autistic', 'auto', 'autoimmune', 'available', 'avoid', 'award', 'awarded', 'away', 'babies', 'baby', 'back', 'backfires', 'background', 'bad', 'badge', 'ban', 'banned', 'banning', 'based', 'basically', 'batman', 'battle', 'be', 'beach', 'bearing', 'bears', 'beats', 'became', 'because', 'become', 'been', 'beer', 'before', 'begins', 'behind', 'behold', 'being', 'beliefs', 'believe', 'believed', 'belongs', 'benadryl', 'benefits', 'benign', 'bent', 'berries', 'besides', 'best', 'better', 'between', 'beware', 'beyond', 'biased', 'big', 'bigger', 'bill', 'billboard', 'billions', 'bin', 'bio', 'biologically', 'biologicals', 'biologist', 'bit', 'bizarro', 'black', 'blaming', 'blank', 'blanket', 'blew', 'blind', 'blog', 'blogger', 'bloodstream', 'blown', 'board', 'bob', 'body', 'book', 'boom', 'boost', 'bot', 'both', 'bother', 'bothered', 'bothering', 'bots', 'bovine', 'bowel', 'boy', 'brain', 'brave', 'braxton', 'bring', 'bringing', 'bro', 'broad', 'broken', 'brother', 'brought', 'bs', 'buck', 'built', 'bullshit', 'bunch', 'bungling', 'buries', 'burtons', 'bury', 'business', 'but', 'buy', 'by', 'california', 'call', 'called', 'calls', 'came', 'camp', 'campaign', 'can', 'canada', 'canadian', 'canadians', 'cancels', 'cancer', 'cancers', 'canned', 'cannot', 'captured', 'care', 'carefully', 'cares', 'carrier', 'carry', 'case', 'cases', 'casting', 'cat', 'category', 'cause', 'caused', 'causes', 'causing', 'cautious', 'cdc', 'celebs', 'celeste', 'cells', 'censor', 'certain', 'certainly', 'certainty', 'cervical', 'cesspool', 'chair', 'challenge', 'challenges', 'chances', 'channel', 'charity', 'check', 'cheers', 'cheeseburger', 'chemical', 'chemist', 'chicken', 'chickenpox', 'child', 'childhood', 'children', 'childrens', 'chili', 'chill', 'chimpanzee', 'chinese', 'choice', 'choose', 'chose', 'cia', 'científicos', 'circle', 'circulating', 'cited', 'citizens', 'civil', 'claim', 'claiming', 'claims', 'clear', 'clearly', 'clinical', 'close', 'cocktail', 'cogently', 'cold', 'colors', 'com', 'come', 'comes', 'comment', 'commenter', 'comments', 'commerce', 'committed', 'common', 'companies', 'company', 'compare', 'compel', 'compete', 'compilación', 'completely', 'comprehend', 'compromised', 'computer', 'concentration', 'concept', 'concern', 'concerned', 'conclusion', 'concurrent', 'condition', 'conditions', 'confession', 'confidence', 'confirmed', 'confront', 'congressional', 'connection', 'consecutive', 'consider', 'considered', 'conspiracy', 'conspiratard', 'conspirawhiners', 'contact', 'contain', 'contains', 'context', 'continue', 'contracting', 'contribute', 'contrived', 'control', 'controversial', 'controversy', 'convinced', 'convincing', 'copy', 'corners', 'corona', 'coronavirus', 'corrects', 'correlates', 'corrupt', 'cost', 'cough', 'could', 'council', 'count', 'counter', 'countries', 'country', 'course', 'court', 'courts', 'cover', 'coverage', 'covering', 'covert', 'covid', 'covid19', 'crap', 'crazy', 'create', 'created', 'creative', 'credibility', 'credible', 'creepy', 'crime', 'cringepics', 'critic', 'critique', 'crow', 'cruel', 'culprit', 'cunt', 'cure', 'cured', 'current', 'currently', 'cut', 'dahl', 'damage', 'damages', 'damaging', 'damn', 'dangerous', 'dangers', 'dares', 'data', 'date', 'daughter', 'day', 'daycare', 'days', 'ddt', 'de', 'dead', 'deadly', 'deal', 'dear', 'death', 'debate', 'debating', 'debunk', 'debunked', 'debunking', 'december', 'deception', 'deem', 'deemed', 'defamatory', 'defamed', 'defend', 'defense', 'definitive', 'delay', 'delayed', 'deliberate', 'deliberately', 'delicious', 'delivery', 'delusional', 'demand', 'denier', 'deniers', 'dental', 'dependent', 'depopulation', 'der', 'derp', 'described', 'deserve', 'desperately', 'destroy', 'detail', 'detailing', 'detox', 'devastating', 'develop', 'developed', 'developing', 'development', 'developmentally', 'diabetes', 'diatribe', 'did', 'didn', 'die', 'died', 'dies', 'diesese', 'diet', 'different', 'dihydrogen', 'dimes', 'directed', 'director', 'disability', 'disabled', 'disagreeing', 'disappear', 'discovery', 'discredit', 'discussing', 'discussion', 'disease', 'diseases', 'disgusting', 'dismissal', 'dismissing', 'disney', 'disneyland', 'disorders', 'dissolving', 'distributing', 'dna', 'do', 'docs', 'doctor', 'doctors', 'documentary', 'documents', 'does', 'doesn', 'dog', 'dogmatic', 'doing', 'dollar', 'don', 'donates', 'dont', 'dose', 'doses', 'double', 'doubled', 'doubt', 'down', 'dozen', 'dr', 'drank', 'drastically', 'dre', 'dreamed', 'drill', 'drink', 'drivers', 'drug', 'drugs', 'dtap', 'due', 'dumb', 'dystopian', 'each', 'earns', 'easily', 'easy', 'eat', 'ebola', 'ed', 'edit', 'educating', 'education', 'educational', 'effect', 'effective', 'effects', 'efficacy', 'either', 'ekg', 'el', 'elaborate', 'elementary', 'elements', 'else', 'emergence', 'emergency', 'emerging', 'employee', 'encountered', 'encouraged', 'endorses', 'enemy', 'engage', 'engineering', 'enough', 'enrich', 'enrollment', 'entire', 'entirely', 'environment', 'epi', 'epidemic', 'epidemics', 'epiphany', 'equal', 'equate', 'er', 'established', 'establishment', 'ethicist', 'ethylmercury', 'eugenics', 'even', 'eventually', 'ever', 'everloving', 'every', 'everybody', 'everyone', 'everything', 'evidence', 'ex', 'exactly', 'except', 'exceptable', 'excited', 'excrement', 'executive', 'exemption', 'exemptions', 'exercise', 'exhaustively', 'expect', 'expected', 'expensive', 'experienced', 'expert', 'expired', 'explain', 'explained', 'explanations', 'exposed', 'exposing', 'exposure', 'extend', 'extensively', 'extent', 'extremely', 'eye', 'eyes', 'facebook', 'facilities', 'fact', 'factor', 'facts', 'fail', 'fails', 'fairy', 'faith', 'fake', 'fall', 'fallacies', 'falling', 'false', 'families', 'family', 'famous', 'faq', 'far', 'farm', 'fascist', 'fascists', 'fatal', 'father', 'fault', 'favor', 'fda', 'fear', 'fecal', 'federal', 'feed', 'feeding', 'feel', 'feeling', 'felt', 'festival', 'fetus', 'fight', 'fighting', 'figure', 'film', 'filthy', 'financed', 'find', 'findings', 'fine', 'fire', 'first', 'fit', 'fits', 'five', 'fix', 'fixing', 'flawed', 'flu', 'fluoride', 'folks', 'follow', 'following', 'fond', 'font', 'food', 'foolish', 'foot', 'for', 'force', 'forced', 'forcing', 'forget', 'form', 'former', 'forms', 'fortunately', 'found', 'foundation', 'founder', 'four', 'fournier', 'fragile', 'frantically', 'fraud', 'fraudulent', 'free', 'freely', 'freezer', 'friend', 'friends', 'frightening', 'from', 'fuck', 'fucked', 'fuckers', 'fucking', 'fuel', 'full', 'fully', 'funded', 'funding', 'fundraise', 'fundraising', 'further', 'future', 'fwd', 'fwiw', 'galloping', 'gallops', 'gambling', 'gap', 'gardasil', 'garlic', 'gates', 'gave', 'general', 'generated', 'genius', 'german', 'get', 'gets', 'getting', 'ghettos', 'girl', 'gish', 'gits', 'give', 'giving', 'glad', 'glidden', 'global', 'glorious', 'glyphosate', 'gmo', 'gmomyths', 'go', 'god', 'godfather', 'godwin', 'goes', 'going', 'goldman', 'gone', 'good', 'got', 'gotta', 'gov', 'government', 'governments', 'graduate', 'graph', 'graphic', 'graphs', 'great', 'greater', 'grey', 'grid', 'grossly', 'groundbreaking', 'group', 'grow', 'growing', 'grown', 'guilt', 'gummy', 'guts', 'guy', 'guys', 'h1n1', 'had', 'hadn', 'hair', 'half', 'han', 'handed', 'handing', 'hands', 'hanks', 'happened', 'happy', 'harassment', 'hardly', 'harmful', 'harming', 'harper', 'harvard', 'has', 'hasn', 'hasnt', 'have', 'haven', 'having', 'he', 'head', 'heads', 'health', 'healthy', 'healthyskepticism', 'hear', 'heard', 'hearing', 'hearings', 'heavily', 'held', 'hell', 'hello', 'help', 'henrycorp', 'hep', 'hepatitis', 'her', 'herd', 'here', 'hero', 'heroes', 'hey', 'hidden', 'high', 'hillary', 'hilleman', 'him', 'himself', 'hipsters', 'his', 'history', 'hit', 'hitler', 'hiv', 'hive', 'hmm', 'hmmm', 'hoax', 'holocaust', 'holy', 'homeopaths', 'honestly', 'hooks', 'hopefully', 'horsecrap', 'horses', 'host', 'hours', 'how', 'however', 'hpv', 'huge', 'human', 'humanity', 'humans', 'hurts', 'hydration', 'hygiene', 'hype', 'hypocrites', 'hysterical', 'idea', 'identifies', 'ideology', 'idiots', 'if', 'ignorance', 'ignorant', 'ignore', 'ignored', 'ignores', 'ill', 'illegal', 'illness', 'illogical', 'illusions', 'im', 'immediately', 'immune', 'immunity', 'immunizations', 'immunize', 'immunologist', 'immunology', 'impact', 'improved', 'in', 'inaccuracies', 'including', 'incompetent', 'incorrect', 'increase', 'increased', 'increasing', 'indeed', 'indication', 'individual', 'individuals', 'induced', 'industry', 'infant', 'infantile', 'infectious', 'inflammatory', 'influenza', 'inform', 'information', 'ingredients', 'inherent', 'initiative', 'inject', 'injected', 'injecting', 'injection', 'injections', 'injured', 'injury', 'insane', 'insecticide', 'insert', 'inside', 'instances', 'instant', 'instead', 'institute', 'institutions', 'intelligence', 'intentionally', 'interest', 'interested', 'interpreting', 'interventions', 'into', 'introduced', 'invalid', 'investigate', 'investigated', 'ipsos', 'iraq', 'ironic', 'ironically', 'irrefutable', 'is', 'isn', 'issues', 'it', 'italian', 'its', 'itself', 'jab', 'jail', 'january', 'japanese', 'jeff', 'jenny', 'jewish', 'jim', 'job', 'johnson', 'joining', 'joseph', 'jr', 'juicing', 'jumps', 'just', 'juts', 'keep', 'keeping', 'keeps', 'kennedy', 'kept', 'kevin', 'kick', 'kid', 'kidnapping', 'kidneys', 'kids', 'kill', 'killed', 'kills', 'kinds', 'kitchen', 'knew', 'know', 'knowledge', 'knowledgeable', 'known', 'knows', 'la', 'lab', 'label', 'lack', 'laden', 'language', 'large', 'larger', 'largest', 'las', 'last', 'later', 'laughing', 'law', 'laws', 'lead', 'learn', 'learned', 'leave', 'led', 'left', 'legally', 'legends', 'legitimate', 'lengths', 'let', 'lethal', 'lets', 'letter', 'lettering', 'letting', 'level', 'license', 'lid', 'lies', 'life', 'lifestyle', 'lifting', 'like', 'likely', 'line', 'link', 'linked', 'linking', 'links', 'list', 'listens', 'literally', 'literature', 'little', 'live', 'living', 'll', 'local', 'logic', 'logical', 'lol', 'londonstan', 'long', 'longer', 'look', 'looked', 'looking', 'loosing', 'lose', 'lost', 'lot', 'lots', 'lousy', 'love', 'low', 'lowered', 'lucifer', 'lumped', 'lymphatic', 'ma', 'mad', 'made', 'maersk', 'mafia', 'magic', 'main', 'mainstream', 'major', 'majority', 'make', 'makes', 'making', 'maliciously', 'managed', 'mandate', 'mandated', 'mandatory', 'manipulation', 'manufactured', 'manufacturer', 'manufacturers', 'many', 'map', 'march', 'market', 'marvelous', 'massachusetts', 'masses', 'massive', 'math', 'matrix', 'matter', 'maurice', 'may', 'maybe', 'mccarthy', 'me', 'mean', 'means', 'meant', 'measles', 'media', 'medical', 'medicine', 'meet', 'meeting', 'melanie', 'meninigits', 'ment', 'mention', 'merck', 'mercola', 'mercury', 'message', 'meta', 'metal', 'methodically', 'microchip', 'might', 'mighty', 'mild', 'mildly', 'milk', 'millennial', 'million', 'millions', 'mind', 'minded', 'minute', 'misinformation', 'mistrust', 'mmmk', 'mmr', 'modern', 'mom', 'moment', 'moms', 'monday', 'mondays', 'money', 'mongering', 'monkey', 'monkeys', 'monopoly', 'monoxide', 'monsanto', 'month', 'more', 'moreover', 'mortality', 'mosquitoes', 'most', 'mother', 'movement', 'movie', 'ms', 'msm', 'much', 'mucus', 'multi', 'multiplied', 'mumps', 'murdering', 'my', 'myself', 'mystery', 'myth', 'myths', 'músicos', 'naa', 'name', 'named', 'nanocovax', 'nanogen', 'nap', 'national', 'nationalautism', 'nations', 'natural', 'naturally', 'naturalnews', 'naturalpath', 'navy', 'near', 'nearly', 'necessarily', 'necessary', 'need', 'needed', 'needles', 'needs', 'negative', 'nephew', 'nerve', 'neurotoxins', 'never', 'new', 'newborn', 'news', 'newsfeed', 'next', 'nickel', 'niece', 'nightmare', 'no', 'nobody', 'nominal', 'non', 'nonsense', 'normal', 'nose', 'not', 'note', 'nothing', 'noun', 'now', 'number', 'numbers', 'numerous', 'nurse', 'nurses', 'nuts', 'nutshell', 'ny', 'object', 'obvious', 'obviously', 'of', 'off', 'offered', 'officials', 'often', 'oh', 'oil', 'okay', 'oklahoma', 'old', 'older', 'on', 'once', 'one', 'ones', 'online', 'only', 'onto', 'op', 'openly', 'opinion', 'opinión', 'opt', 'or', 'oral', 'orange', 'ordeal', 'order', 'org', 'organisation', 'organization', 'original', 'osama', 'other', 'others', 'otherwise', 'ottawa', 'our', 'out', 'outbreak', 'outside', 'over', 'overdose', 'overload', 'oversight', 'overview', 'own', 'owner', 'owners', 'owns', 'oxford', 'package', 'page', 'paid', 'pakistan', 'pandemic', 'pandering', 'panel', 'paper', 'papers', 'para', 'paraded', 'paragraph', 'paralysis', 'paralytic', 'paralyzed', 'parent', 'parents', 'part', 'participated', 'partner', 'passed', 'passion', 'passports', 'past', 'pasta', 'pathetic', 'payer', 'payouts', 'pcbs', 'pdf', 'peanut', 'peddling', 'pediatric', 'pediatrics', 'peer', 'penicillin', 'people', 'percentage', 'perfect', 'perfectly', 'period', 'persecuted', 'persecution', 'person', 'personal', 'personally', 'pertussis', 'pesticide', 'pet', 'petition', 'pets', 'pfizer', 'pharma', 'pharmaceutical', 'pharmaceuticals', 'pharmacutical', 'phase', 'philosophical', 'physicians', 'picture', 'piece', 'piktochart', 'pirates', 'place', 'plan', 'planned', 'plants', 'platform', 'play', 'please', 'pneumonia', 'podcast', 'point', 'points', 'poison', 'poisoning', 'poisons', 'police', 'polio', 'poliomyelitis', 'poll', 'pompous', 'poor', 'populace', 'popular', 'population', 'posed', 'possession', 'possible', 'post', 'posted', 'poster', 'posters', 'posting', 'posts', 'potentially', 'powerpoint', 'pox', 'ppm', 'practice', 'practitioners', 'prager', 'preschool', 'present', 'presentation', 'presented', 'preservative', 'president', 'press', 'pressure', 'pretty', 'prevent', 'preventable', 'prevented', 'prevents', 'principal', 'prior', 'prioritize', 'private', 'pro', 'probably', 'problem', 'problems', 'produce', 'produced', 'product', 'products', 'profile', 'profit', 'profitable', 'profits', 'program', 'programmer', 'programs', 'progress', 'promising', 'promote', 'promoters', 'promotes', 'prompting', 'proof', 'propaganda', 'propagandist', 'propagandists', 'propagate', 'prosecuted', 'protect', 'protection', 'protective', 'protest', 'prove', 'proven', 'proves', 'provide', 'providing', 'prufe', 'pseudo', 'pseudoscience', 'psyche', 'public', 'publication', 'published', 'pulled', 'punishment', 'pure', 'purely', 'push', 'pushed', 'put', 'putting', 'que', 'question', 'questions', 'quickly', 'quite', 'quote', 'ra', 'race', 'radical', 'rag', 'rage', 'random', 'ranging', 'rat', 'rate', 'rates', 'rather', 'ratio', 'raw', 're', 'reactions', 'read', 'reading', 'real', 'reality', 'realize', 'realized', 'really', 'reason', 'reasoned', 'reasons', 'rebuke', 'recalled', 'recent', 'recently', 'recibido', 'reckless', 'recombinant', 'recommendation', 'recommends', 'recount', 'red', 'redacted', 'reddit', 'refuse', 'refute', 'refuted', 'refutes', 'regarding', 'regardless', 'registry', 'regulated', 'reignites', 'reject', 'related', 'relations', 'relationship', 'release', 'released', 'reliable', 'reliant', 'religious', 'remain', 'remove', 'removed', 'renowned', 'repeatedly', 'replicated', 'report', 'reports', 'required', 'requirement', 'research', 'researched', 'researchers', 'reservations', 'resource', 'resourse', 'respond', 'response', 'rest', 'restaurants', 'restricted', 'results', 'retarded', 'retards', 'rethefuckfuse', 'returned', 'review', 'reviewed', 'reviews', 'revoked', 'rfk', 'right', 'rights', 'rise', 'risk', 'roald', 'rob', 'robots', 'rothchild', 'route', 'routinely', 'rt', 'run', 'running', 'rural', 'sad', 'saddest', 'sadly', 'safe', 'safer', 'safety', 'said', 'sales', 'same', 'sanitation', 'satire', 'satirical', 'say', 'saying', 'says', 'sb', 'scam', 'scare', 'scared', 'scary', 'sceptical', 'schedule', 'scheme', 'schneider', 'school', 'schools', 'science', 'scientific', 'scientifically', 'scientist', 'scientists', 'scratch', 'scumbags', 'seals', 'seattleorganicrestaurants', 'second', 'secret', 'secrets', 'section', 'secure', 'see', 'seeing', 'seeking', 'seems', 'seen', 'selling', 'send', 'sending', 'sent', 'sentence', 'sentiment', 'sentiments', 'series', 'services', 'set', 'settled', 'settlement', 'several', 'severely', 'sex', 'sexually', 'shameless', 'share', 'she', 'shed', 'shedding', 'sheeple', 'shelf', 'shill', 'shills', 'shit', 'shitoly', 'shitstorm', 'shitty', 'shock', 'shocking', 'shooting', 'short', 'shot', 'shots', 'should', 'shouldn', 'showing', 'shown', 'shows', 'shut', 'sick', 'side', 'sidebar', 'sides', 'sids', 'sign', 'signals', 'signed', 'signs', 'similar', 'simple', 'simply', 'since', 'sister', 'site', 'six', 'size', 'skin', 'skyrocketed', 'slightly', 'slow', 'snifflies', 'so', 'sobre', 'social', 'solum', 'solution', 'solving', 'somatotropin', 'some', 'someone', 'something', 'son', 'soon', 'sophomoric', 'sorry', 'sorts', 'sound', 'sources', 'south', 'spam', 'spanish', 'special', 'specific', 'specifically', 'spectrum', 'speeches', 'spill', 'spinning', 'sprayed', 'spread', 'spreading', 'spreads', 'stab', 'stake', 'stand', 'stands', 'star', 'stares', 'started', 'starts', 'state', 'states', 'stating', 'status', 'stay', 'stems', 'sterile', 'sterilise', 'sterilize', 'sticking', 'still', 'stood', 'stop', 'stopped', 'stories', 'story', 'strain', 'strains', 'strategic', 'strategy', 'stretch', 'stroke', 'stronger', 'struck', 'student', 'students', 'studies', 'study', 'stuff', 'stupid', 'style', 'sub', 'submit', 'submitting', 'subreddit', 'subs', 'substance', 'substances', 'success', 'such', 'sudan', 'suddenly', 'sue', 'suggestions', 'sum', 'summary', 'support', 'supposed', 'supreme', 'sure', 'surprised', 'surprising', 'surrounding', 'survey', 'susceptible', 'sustained', 'swine', 'symptoms', 'syndrome', 'system', 'systems', 'table', 'tactic', 'take', 'taken', 'takes', 'taliban', 'talk', 'talking', 'tampered', 'targeted', 'targets', 'tattoo', 'tax', 'tea', 'teal', 'team', 'technology', 'teens', 'teething', 'telekinetic', 'telephone', 'tell', 'telling', 'tells', 'terrible', 'terribly', 'terrifying', 'test', 'tested', 'tetanus', 'textbooks', 'textos', 'th', 'than', 'that', 'the', 'theaters', 'their', 'them', 'themselves', 'then', 'theorists', 'theory', 'there', 'therefor', 'therefore', 'these', 'they', 'thimerosal', 'thimerosil', 'thing', 'things', 'think', 'thinking', 'thinks', 'third', 'this', 'those', 'though', 'thought', 'thousand', 'thousands', 'thread', 'threaten', 'three', 'through', 'til', 'tim', 'time', 'times', 'tiny', 'to', 'today', 'together', 'told', 'toll', 'tom', 'toni', 'too', 'took', 'toolbox', 'tooth', 'top', 'topic', 'torn', 'total', 'totally', 'toughen', 'toward', 'towards', 'town', 'toxic', 'tptb', 'track', 'tracker', 'transmitted', 'treat', 'treated', 'trial', 'tribeca', 'tries', 'trigger', 'trouble', 'truck', 'true', 'truly', 'trump', 'trumps', 'trust', 'truth', 'truthaboutvaccines', 'try', 'trying', 'tube', 'turn', 'turned', 'twice', 'twitter', 'two', 'type', 'types', 'typical', 'tyranny', 'tyrants', 'uh', 'uk', 'ultimately', 'un', 'unable', 'undeniable', 'understand', 'undoubtedly', 'uneducated', 'unequipped', 'unethical', 'unfit', 'uni', 'unique', 'united', 'university', 'unknown', 'unless', 'unlikely', 'unnecessary', 'unscientific', 'untested', 'until', 'unvaccinated', 'up', 'update', 'updated', 'upon', 'urged', 'us', 'usa', 'use', 'used', 'user', 'username', 'users', 'uses', 'ushers', 'using', 'utter', 'vaccinate', 'vaccinated', 'vaccinates', 'vaccination', 'vaccinations', 'vaccinators', 'vaccine', 'vaccines', 'vaccinesafetynet', 'vacuna', 'vacunas', 'vacvimes', 'validated', 'vapp', 'variants', 'various', 'vast', 'vax', 'vaxer', 'vaxx', 'vaxxed', 'vaxxer', 'vaxxers', 'vaxxing', 've', 'vegan', 'vegetables', 'vehement', 'verb', 'verdict', 'verified', 'verifies', 'very', 'vet', 'via', 'video', 'vietnam', 'vilified', 'vioxx', 'virons', 'virus', 'viruses', 'vitamin', 'volunteers', 'vote', 'vs', 'wait', 'waiting', 'wakefield', 'wakefields', 'walk', 'want', 'wanted', 'wants', 'war', 'warning', 'warrants', 'was', 'wash', 'wasn', 'water', 'wave', 'waves', 'way', 'we', 'wealthy', 'wears', 'website', 'websites', 'week', 'weeks', 'welcome', 'well', 'wendy', 'were', 'weren', 'western', 'what', 'whatever', 'when', 'where', 'whether', 'which', 'while', 'whilst', 'whistle', 'whistleblower', 'white', 'who', 'whole', 'whomever', 'whomst', 'whooping', 'why', 'widespread', 'wife', 'wild', 'will', 'willful', 'willing', 'win', 'winded', 'wish', 'with', 'within', 'without', 'women', 'won', 'wonder', 'wondering', 'wonders', 'woo', 'woodwork', 'word', 'work', 'working', 'works', 'world', 'worst', 'worth', 'would', 'wrath', 'writing', 'written', 'wrong', 'wrote', 'wsj', 'www', 'xpost', 'yea', 'yeah', 'year', 'years', 'yellow', 'yep', 'yes', 'yet', 'yo', 'yoda', 'you', 'your', 'yourself', 'youtube', 'zero', 'zika']\n"
     ]
    }
   ],
   "source": [
    "# Identify a scheme to categorize each comment as positive or negative\n",
    "#uses count vectorizer transformer (page 58)\n",
    "corpus = df['title']\n",
    "vectorizer = CountVectorizer()\n",
    "vectors = vectorizer.fit_transform(corpus)\n",
    "\n",
    "\n",
    "\n",
    "# Look at vectorized words, I'm using this to determine my positive and negative words (pg 113)\n",
    "print(vectorizer.get_feature_names())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                text  \\\n",
      "0     Health Canada approves AstraZeneca COVID-19 vaccine                              \n",
      "1     COVID-19 in Canada: 'Vaccination passports' a near certainty says bio-ethicist   \n",
      "2     Coronavirus variants could fuel Canada's third wave                              \n",
      "3     Canadian government to extend COVID-19 emergency benefits                        \n",
      "4     Canada: Pfizer is 'extremely committed' to meeting vaccine delivery targets      \n",
      "...                                                                           ...      \n",
      "1479  Comment                                                                          \n",
      "1480  Comment                                                                          \n",
      "1481  Comment                                                                          \n",
      "1482  Comment                                                                          \n",
      "1483  Comment                                                                          \n",
      "\n",
      "      super  good  special  fantastic  perfect  totalpositive  bad  ashamed  \\\n",
      "0     0      0     0        0          0        0              0    0         \n",
      "1     0      0     0        0          0        0              0    0         \n",
      "2     0      0     0        0          0        0              0    0         \n",
      "3     0      0     0        0          0        0              0    0         \n",
      "4     0      0     0        0          0        0              0    0         \n",
      "...  ..     ..    ..       ..         ..       ..             ..   ..         \n",
      "1479  0      0     0        0          0        0              0    0         \n",
      "1480  0      0     0        0          0        0              0    0         \n",
      "1481  0      0     0        0          0        0              0    0         \n",
      "1482  0      0     0        0          0        0              0    0         \n",
      "1483  0      0     0        0          0        0              0    0         \n",
      "\n",
      "      worst  absurdity  attack  cruel  danger  totalnegative  TotalScore  \n",
      "0     0      0          0       0      0       0              0           \n",
      "1     0      0          0       0      0       0              0           \n",
      "2     0      0          0       0      0       0              0           \n",
      "3     0      0          0       0      0       0              0           \n",
      "4     0      0          0       0      0       0              0           \n",
      "...  ..     ..         ..      ..     ..      ..             ..           \n",
      "1479  0      0          0       0      0       0              0           \n",
      "1480  0      0          0       0      0       0              0           \n",
      "1481  0      0          0       0      0       0              0           \n",
      "1482  0      0          0       0      0       0              0           \n",
      "1483  0      0          0       0      0       0              0           \n",
      "\n",
      "[1484 rows x 16 columns]\n",
      "                                                                                text  \\\n",
      "0     Health Canada approves AstraZeneca COVID-19 vaccine                              \n",
      "1     COVID-19 in Canada: 'Vaccination passports' a near certainty says bio-ethicist   \n",
      "2     Coronavirus variants could fuel Canada's third wave                              \n",
      "3     Canadian government to extend COVID-19 emergency benefits                        \n",
      "4     Canada: Pfizer is 'extremely committed' to meeting vaccine delivery targets      \n",
      "...                                                                           ...      \n",
      "1479  Comment                                                                          \n",
      "1480  Comment                                                                          \n",
      "1481  Comment                                                                          \n",
      "1482  Comment                                                                          \n",
      "1483  Comment                                                                          \n",
      "\n",
      "      super  good  special  fantastic  perfect  totalpositive  bad  ashamed  \\\n",
      "0     0      0     0        0          0        0              0    0         \n",
      "1     0      0     0        0          0        0              0    0         \n",
      "2     0      0     0        0          0        0              0    0         \n",
      "3     0      0     0        0          0        0              0    0         \n",
      "4     0      0     0        0          0        0              0    0         \n",
      "...  ..     ..    ..       ..         ..       ..             ..   ..         \n",
      "1479  0      0     0        0          0        0              0    0         \n",
      "1480  0      0     0        0          0        0              0    0         \n",
      "1481  0      0     0        0          0        0              0    0         \n",
      "1482  0      0     0        0          0        0              0    0         \n",
      "1483  0      0     0        0          0        0              0    0         \n",
      "\n",
      "      worst  absurdity  attack  cruel  danger  totalnegative  TotalScore  \n",
      "0     0      0          0       0      0       0              0           \n",
      "1     0      0          0       0      0       0              0           \n",
      "2     0      0          0       0      0       0              0           \n",
      "3     0      0          0       0      0       0              0           \n",
      "4     0      0          0       0      0       0              0           \n",
      "...  ..     ..         ..      ..     ..      ..             ..           \n",
      "1479  0      0          0       0      0       0              0           \n",
      "1480  0      0          0       0      0       0              0           \n",
      "1481  0      0          0       0      0       0              0           \n",
      "1482  0      0          0       0      0       0              0           \n",
      "1483  0      0          0       0      0       0              0           \n",
      "\n",
      "[1484 rows x 16 columns]\n",
      "Total Score: -15\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'text' : corpus})\n",
    "\n",
    "# check for positive words and negative words\n",
    "# Positive Words\n",
    "df['super'] = df.text.str.count('super')\n",
    "df['good'] = df.text.str.count('good')\n",
    "df['special']= df.text.str.count('special')\n",
    "df['fantastic']= df.text.str.count('fantastic')\n",
    "df['perfect']= df.text.str.count('perfect')\n",
    "df['totalpositive'] = (df.super + df.good + df.special + df.fantastic + df.perfect)\n",
    "\n",
    "# Negative Words\n",
    "df['bad'] = df.text.str.count('bad')\n",
    "df['ashamed'] = df.text.str.count('ashamed')\n",
    "df['worst'] = df.text.str.count('worst')\n",
    "df['absurdity'] = df.text.str.count('absurdity')\n",
    "df['ashamed'] = df.text.str.count('ashamed')\n",
    "df['attack'] = df.text.str.count('attack')\n",
    "df['cruel'] = df.text.str.count('cruel')\n",
    "df['danger'] = df.text.str.count('danger')\n",
    "df['cruel'] = df.text.str.count('cruel')\n",
    "\n",
    "df['totalnegative'] = (df.bad + df.ashamed + df.worst + df.absurdity + df.attack + df.cruel + df.danger)\n",
    "#get a total score by adding the positives and subtracting the negative words\n",
    "df['TotalScore'] = (df.totalpositive) - (df.totalnegative)\n",
    "df = pd.DataFrame(df)\n",
    "print(df)\n",
    "\n",
    "Z = sum(df['TotalScore'])\n",
    "\n",
    "# Implement your sentiment analysis with code and display the results. Note: DailyComments.csv is a purposely small file, so you will be able to clearly see why the results are what they are.\n",
    "print(df)\n",
    "print(\"Total Score:\",Z)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}